deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1) - deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail=FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
1
View(ravenData)
mdl <- glm(ravenWinNum ~ ravenScore, binomial, ravenData)
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95, 1)
rpois(n, lambda)
var(rpois(1000, 50))'
var(rpois(1000, 50))
a
var(rpois(1000, 50))
head(hits)
class(hits[,'date'])
as.integer(head(hits[,'date']))
glm(visits ~ date, poisson, hits)
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
confint(mdl, 'date')
exp(confint(mdl, 2)
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,]
mdl$fitted.values[704]
lambda <- mdl$fitted.values[704
lambda <- mdl$fitted.values[704]
qpois(.95,
lambda)
mdl2 <- glm(simplystats ~ date, poisson, hits, offset=log(visits+1))
qpois(.95, mdl2$fitted.values[704])
plot(child ~ parent, galton)
plot(jitter(child,4) ~ parent,galton)
regrline <- lm(child ~
parent, galton)"
regrline <- lm(child ~
parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
install_from_swirl("Statistical Inference")
swirl()
1
1
1
1
1
1
1
1
1
0
info()
skip()
deck
13
52
1/13
0
`2/52
12/52
4/52
2/50
2/51
1
1
1
1
library(swirl)
info()
main()
main()
1
1
1
1
1
1
1
1
12
2
2
2.64
.64
.64
mypdf
integrate(mypdf,0,1.6)
1.414214
main()
P(+|D)*P(D)
.997*.001
(1-.985)*(1-.001)
.000997/(.000997+.014985)
1
1
15
15/6
3.5
expect_dice
dice_high
expect_dice(dice_high)
expect_dice(dice_loq)
expect_dice(dice_low)
3.5
integrate(myfunc,0,2)
spop
mean(spop)
allsam
apply(allsam,1,mean)
\mean(smeans)
mean(smeans)
dice_sqr
ex2_fair <- sum(dice_fair * dice_sqr)
ex2_fair-3.5^2
sum(dice_high * dice_sqr)-edh^2
sd(apply(matrix(rnorm(10000),1000),1,mean))
1/sqrt(10)
1/sqrt(120)
sd(apply(matrix(runif(10000),1000),1,mean))
2/sqrt(10)
sd(apply(matrix(rpois(10000,4),1000),1,mean))
1
1
1/(2*sqrt(10))
sd(apply(matrix(sample(0:1,10000,TRUE),1000),1,mean))
1
1
1
1
1
1
1
(5,x)*(.8)^x*(.2)(5-x)
choose(5,x)*(.8)^x*(.2)(5-x) for x=3,4,5
0.94208
pbinom(2,size=5,prob=.8,lower.tail=FALSE)
qnorm(.10)
0
qnorm(.975,mean=3,sd=2)
6.92
pnorm(1200,mean=1020,sd=50,lower.tail=FALSE)
pnorm((1200-1020)/50,lower.tail=FALSE)
qnorm(.75,mean=1020,sd=50)
.53
.53
ppois(3,2.5 * 4)
pbinom(5,1000,.01)
ppois(5,1000*.01)
main()
main()
1
1
1
1
coinPlot(10)
coinPlot(10000)
1
1
1
1
qnorm(.95)
1
1
1
1
1
.6 + c(-1,1)*qnorm(.975)*sqrt(.6*.4/100)
binom.test(60,100)$conf.int
mywald(.2)
ACCompar(20)
1
1
1
1
lamb <- 5/94.32
lamb +c(-1,1)*qnorm(.975)*sqrt(lamb/94.32)
poisson.test(5,94.32)$conf
main()
1
1
1
1
1
2
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
(32-30)/(10/4)
1
1
1
1
1
1
14
16
15
qt(.95,15)
1
1
1
dim(fs)
t.test(fs$sheight-fs$fheight)
1
1
11
1
1
1
11.7885 * sd(fs$sheight-fs$fheight)/sqrt(1078)
mybin
8
1
1
1
1
myplot(2)
myplot(20)
myplot2(2)
qt(.975,2)
myplot2(20)
1
1
sleep
sleepPlot.R
range(g1)
range(g1)
range(g2)
difference <- g2-g1
mean(difference)
s <- sd(difference)
mn + c(-1,1)*qt(.975,9)*s/sqrt(10)
t.test(difference)$conf.int
1
1
1
1
1
sp <- 7*15.34^2 + 20*18.23^2
1
1
11
ns <- 8+21-2
sp <- sqrt(sp/ns)
132.86-127.44+c(-1,1)*qt(.975,ns)*sp*sqrt(1/8+1/21)
sp <- sqrt((9*var(g1)+9*var(g2))/18)
md + c(-1,1)*qt(.975,18)*sp*sqrt(1/5)
t.test(g2,g1,paired=FALSE,var.equal=TRUE)$conf
t.test(g2,g1,paired=TRUE)$conf
num <- (15.34^2/8 + 18.23^2/21)^2
den <- 15.34^4/8^2/7 + 18.23^4/21^2/20
mydf <- num/den
132.86-127.44 +c(-1,1)*qt(.975,mydf)*sqrt(15.34^2/8 + 18.23^2/21)
1
1
1
1
1
1
1
1
pt(2.5, 15, lower.tail=FALSE)
1
1
1
qnorm(.95)
qnorm(.99)
pnorm(2)
pnorm(2,lower.tail=FALSE)
mybin
pbinom(6,size=8,prob=.5,lower.tail=FALSE)
pbinom(7,size=8,prob=.5,lower.tail=TRUE)
ppois(9,5,lower.tail=FALSE)
1
1
11
1
1
1
myplot(34)
myplot(33.3)
myplot(30)
myplot(28)
1
1
1
z <- qnorm(.95)
pnorm(30+z,mean=30,lower.tail=FALSE)
pnorm(30+z,mean=32,lower.tail=FALSE)
pnorm(30+z,mean=32,sd=1,lower.tail=FALSE)
pnorm(30+z*2,mean=32,sd=2,lower.tail=FALSE)
1
power.t.test(n = 16, delta = 2 / 4, sd=1, type = "one.sample", alt = "one.sided")$power
power.t.test(n = 16, delta = 2 , sd=4, type = "one.sample",  alt = "one.sided")$power
power.t.test(n = 16, delta = 100 , sd=200, type = "one.sample",  alt = "one.sided")$power
1
.t.test(power = .8, delta = 2 / 4, sd=1, type = "one.sample", alt = "one.sided")$n
t.test(power = .8, delta = 2 / 4, sd=1, type = "one.sample", alt = "one.sided")$n
power.t.test(power = .8, delta = 2 / 4, sd=1, type = "one.sample",  alt = "one.sided")$n
power.t.test(power = .8, delta = 2, sd=4, type = "one.sample",  alt = "one.sided")$n
power.t.test(power = .8, delta = 100 , sd=200, type = "one.sample",  alt = "one.sided")$n
power.t.test(power = .8, n=26, sd=1, type = "one.sample",  alt = "one.sided")$delta
power.t.test(power = .8, n=27, sd=1, type = "one.sample",  alt = "one.sided")$delta
1
11
1
1
head(pValues)
sum(pValues < 0.05)
sum(p.adjust(pValues,method="bonferroni") < 0.05)
sum(p.adjust(pValues,method="BH") < 0.05)
tail(trueStatus)
table(pValues2 < 0.05, trueStatus)
equiv_val(.048)
24/500
table(p.adjust(pValues2,method=\"bonferroni\") < 0.05, trueStatus)
table(p.adjust(pValues2,method=\"bonferroni\") < 0.05, trueStatus)
table(p.adjust(pValues2,method=\"bonferroni\) < 0.05, trueStatus)
table(p.adjust(pValues2,method=\"bonferroni) < 0.05, trueStatus)
table(p.adjust(pValues2,method=\"bonferroni\") < 0.05, trueStatus)
table(p.adjust(pValues2,method="bonferroni") < 0.05, trueStatus)
table(p.adjust(pValues2,method=\"BH\") < 0.05, trueStatus)
table(p.adjust(pValues2,method="BH=") < 0.05, trueStatus)
table(p.adjust(pValues2,method=\"BH\") < 0.05, trueStatus)
table(p.adjust(pValues2,method="BH
") < 0.05, trueStatus)
"table(p.adjust(pValues2,method=\"BH\") < 0.05, trueStatus)"
"table(p.adjust(pValues2,method=\"BH") < 0.05, trueStatus)"
"table(p.adjust(pValues2,method="BH") < 0.05, trueStatus)"
table(p.adjust(pValues2,method=\"BH\") < 0.05, trueStatus)
table(p.adjust(pValues2,method="BH\") < 0.05, trueStatus)
table(p.adjust(pValues2,method="BH") < 0.05, trueStatus)
11
1
1
sum(1\:6)/6
sum(1:6)/6
print(g2)
1
1
1
1
head(sh)
nh
median(resampledMedians)
median(sh)
am <- sample(fh,nh*B,replace=TRUE)
sam <- sample(fh,nh*B,replace=TRUE)
resam <- matrix(sam,B,nh)
meds <- apply(resam,1,median)
meds <- apply(resam,1,median)
swirl()
1
main()
main()
1
1
1
sum(1\:6)/6
sum(1:6)/6
print(g2)
1
1
1
1
head(sh)
nh
median(resampledMedians)
median(sh)
sam <- sample(fh,nh*B,replace=TRUE)
resam <- matrix(sam,B,nh)
meds <- apply(resam,1,median)
median(meds)-median(fh)
sd(meds)
sd(resampledMedians)
quantile(resampledMedians,c(.025,.975))
quantile(meds,c(.025,.975))
dim(InsectSprays)
names(InsectSprays)
range(Bdata$count)
range(Cdata$count)
BCcounts
group
testStat
obs <- testStat(BCcounts,group)
obs
mean(Bdata$count)-mean(Cdata$count)
sample(group)
perms <- sapply(1 : 10000, function(i) testStat(BCcounts, sample(group)))
mean(perms>obs)
testStat(DEcounts,group)
perms <- sapply(1 : 10000, function(i) testStat(DEcounts, sample(group)))
main
main()
info()
bye()
devtools::install_github("rstudio/rmarkdown")
install.packages("devtools"); devtools::install_github("rstudio/rmarkdown")
library(rmarkdown)
library("devtools", lib.loc="~/R/win-library/3.1")
---
title: 'Statistical Inference Course Project, Part 1: Simulation Exercises'
author: "Wilson"
output:
pdf_document:
fig_height: 4
html_document: default
---
The exponential distribution can be simulated in R with `rexp(n, lambda)` where
`lambda` $\lambda$ is the rate parameter. The mean of exponential distribution is
$1/\lambda$ and the standard deviation is also $1/\lambda$. For this simulation,
we set $\lambda=0.2$. In this simulation, we investigate the distribution of
averages of 40 numbers sampled from exponential distribution with $\lambda=0.2$.
Let's do a thousand simulated averages of 40 exponentials.
```{r}
set.seed(3)
lambda <- 0.2
num_sim <- 1000
sample_size <- 40
sim <- matrix(rexp(num_sim*sample_size, rate=lambda), num_sim, sample_size)
row_means <- rowMeans(sim)
```
The distribution of sample means is as follows.
```{r echo=FALSE}
# plot the histogram of averages
hist(row_means, breaks=50, prob=TRUE,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(row_means))
# theoretical center of distribution
abline(v=1/lambda, col="red")
# theoretical density of the averages of samples
xfit <- seq(min(row_means), max(row_means), length=100)
yfit <- dnorm(xfit, mean=1/lambda, sd=(1/lambda/sqrt(sample_size)))
lines(xfit, yfit, pch=22, col="red", lty=2)
# add legend
legend('topright', c("simulation", "theoretical"), lty=c(1,2), col=c("black", "red"))
```
The distribution of sample means is centered at `r mean(row_means)`
and the theoretical center of the distribution is $\lambda^{-1}$ = `r 1/lambda`.
The variance of sample means is `r var(row_means)` where the theoretical variance
of the distribution is $\sigma^2 / n = 1/(\lambda^2 n) = 1/(0.04 \times 40)$ =
`r 1/(0.04 * 40)`.
Due to the central limit theorem, the averages of samples follow normal
distribution. The figure above also shows the density computed using the histogram and the
normal density plotted with theoretical mean and variance values. Also, the
q-q plot below suggests the normality.
```{r echo=FALSE}
qqnorm(row_means); qqline(row_means)
```
Finally, let's evaluate the coverage of the confidence interval for
$1/\lambda = \bar{X} \pm 1.96 \frac{S}{\sqrt{n}}$
```{r echo=FALSE}
lambda_vals <- seq(4, 6, by=0.01)
coverage <- sapply(lambda_vals, function(lamb) {
mu_hats <- rowMeans(matrix(rexp(sample_size*num_sim, rate=0.2),
num_sim, sample_size))
ll <- mu_hats - qnorm(0.975) * sqrt(1/lambda**2/sample_size)
ul <- mu_hats + qnorm(0.975) * sqrt(1/lambda**2/sample_size)
mean(ll < lamb & ul > lamb)
})
library(ggplot2)
qplot(lambda_vals, coverage) + geom_hline(yintercept=0.95)
```
The 95% confidence intervals for the rate parameter ($\lambda$) to be estimated
($\hat{\lambda}$) are
$\hat{\lambda}_{low} = \hat{\lambda}(1 - \frac{1.96}{\sqrt{n}})$ agnd
$\hat{\lambda}_{upp} = \hat{\lambda}(1 + \frac{1.96}{\sqrt{n}})$.
As can be seen from the plot above, for selection of $\hat{\lambda}$ around 5,
the average of the sample mean falls within the confidence interval at least 95% of the time.
Note that the true rate, $\lambda$ is 5.
library(shinyapps)
shinyapps::setAccountInfo(name='wilsonow', token='6C0CD6A59CA25790135028C8669265C4', secret='VCS2u4Nx1ToLJPULBBOxw9grMZgamxhBDS236SRK')
detach("package:shinyapps", unload=TRUE)
library(shinyapps)
shinyapps::setAccountInfo(name='wilsonow', token='6C0CD6A59CA25790135028C8669265C4', secret='VCS2u4Nx1ToLJPULBBOxw9grMZgamxhBDS236SRK')
shinyapps::deployApp('C:\Users\yuow89\Desktop\New Project')
shinyapps::deployApp('Users\yuow89\Desktop\New Project')
shinyapps::deployApp('C:/Users/yuow89/Desktop/New Project')
]shinyapps::setAccountInfo(name='wilsonow', token='6C0CD6A59CA25790135028C8669265C4', secret='VCS2u4Nx1ToLJPULBBOxw9grMZgamxhBDS236SRK')
shinyapps::setAccountInfo(name='wilsonow', token='6C0CD6A59CA25790135028C8669265C4', secret='VCS2u4Nx1ToLJPULBBOxw9grMZgamxhBDS236SRK')
shinyapps::deployApp('C:/Users/yuow89/Desktop/New Project')
setAccountInfo(name='wilsonow', token='6C0CD6A59CA25790135028C8669265C4', secret='VCS2u4Nx1ToLJPULBBOxw9grMZgamxhBDS236SRK')
deployApp('C:/Users/yuow89/Desktop/New Project')
library(shiny)
runApp("census-app")
runApp()
setwd("C:/Users/yuow89/Desktop/New Project")
# install.packages("shiny")
runApp()
